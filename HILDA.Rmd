---
output:
  html_document:
    keep_md: yes
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 120)
```
# HILDA

Le variabili di Interesse sono edhigh1 (education) e jbmo62 (occupation). 
Come vedi ci sono relativamente pochi immigrati. 
Ti ho inviato un'extraction del pannello (xwaveid e wave). Ci sono 12 osservazioni al massimo ma come vedrai non per tutti.
I salari sono wscei (current weekly wage) e wsfei (Financial year wage) 

Covariates:
ancob: Country of birth
yrivwfst: year first interview
yrivwlst: year last interview
hh*: household...
edcqtyp: Currently studying full or part time
esdtl: Labour force status - detail
esempst: Current employment status
jb*: job... (jbmo62)
helth: Long term health condition
fmfsch: How much schooling father completed
fmmsch: How much schooling mother completed
anlote: Speak language other than English
aneab: How well speaks English
anyoa: Year first came to Australia to live (no anyoan)
anpappn: Australian visa - Primary applicant
anengfn: Is English the first language you learned to speak as a child
edcoqn: Country completed highest education
rtcompn: Retired completely from the workforce
rtyrn: Year retired
jbmoccs: occupational status scale, current main job
tcr: Number of own resident children
tcnr: Number of own non-resident children
hhyng: Age of youngest person in household
hhold: Age of oldest person in household
anmigc: Migration category when you or your family first arrived in Australia: **mostly missings**
fmnsib: How many siblings
edqenr: Ever enrolled in a course of study to obtain a qualification
edcoq: Country completed highest qualification
hgage: Age last birthday at June 30 2012

## Data

* Load the data and make some home cleaning (details omitted).
```{r data_manipulation, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
#library(readstata13)
setwd("~/Dropbox/dropbox mq/Maurizio/")
load("Hilda.RData")
#x=read.dta13("MAURIZIO_HILDA_extraction.dta")
x = x[x$yrivwfst!=-2,]
x$age_at_interview = x$hgage - (2012-x$yrivwfst)

x$anmigc = as.factor(x$anmigc)

# ancob [country of birth] --> 3 categories: AU, anglo, others
missings.ancob=which(as.numeric(x$ancob) <=10)
x = x[-missings.ancob,]
au = c("[1101] Australia")
anglo = c("[2100] United Kingdom", "[2201] Ireland", "[9225] South Africa", "[8102] Canada", "[8104] United States of America")
i.au = which(x$ancob %in% au)
i.anglo = which(x$ancob %in% anglo)
ancob3 = rep("others", nrow(x)) 
ancob3[i.au] = "australians"
ancob3[i.anglo] = "anglo"
x$ancob3 = factor(ancob3)

x$edcoq[is.na(x$edcoq)] = 1 #<----- check
x$edqenr[is.na(x$edqenr)] = 1 #<----- check
x$aneab[i.au] = 1

# anyoa [year of arriva] --> wave-age for non-migrants
x$anyoa[i.au] = 2012 - x$hgage[i.au]
x=x[x$anyoa>1900,]
#WARNNING: i.au no more valid from here on
##Factors##
facto <- c("xwaveid","jbmspay","jbmssec","edcoq")
for (f in facto) x[,f]=as.factor(x[,f])
```

* Create the variable wages_perc: percentile of salary specific to each job [details omitted].
```{r wages_perc, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
##wages_perc
individual_quantiles <- function(x){
	n <- length(x)
	return(rank(x)/n)
}

perc_by_job =by(x, x$jbmo62, function(x)quantile(x$wsfei, prob=c(0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1)))
jobs=levels(x$jbmo62)
jobs=jobs[substr(jobs,1,2)!="[-"]
x$wages_perc = rep(NA, nrow(x))
for (j in jobs){
	ii <- which(x$jbmo62 == j)
	wages <- x[ii,"wsfei"]
	wages_perc <- individual_quantiles(wages)
	x[ii,"wages_perc"] <- wages_perc
}
x=x[!is.na(x$wages_perc),]
```

* Plot wages_perc vs wages (each job-code [1 digit] is a different color):
```{r plot_wages_perc, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
# Try plotting with colours based on the job code
x$job1digit=as.factor(sapply(x$jbmo62,function(x)substr(x,2,2)))
x$job2digits=as.factor(sapply(x$jbmo62,function(x)substr(x,2,3)))
jobs=levels(x$job1digit)
n_jobs = length(jobs)
plot(0,0,xlim=c(0,log(1E6)),ylim=c(0,1), xlab="log(wages)", ylab="wages_perc")
cols = rainbow(n_jobs)
legend('topleft',legend=1:length(cols),fill=cols)
for (j in jobs){
  ii <- which(x$job1digit == j)
	wages <- sort(x[ii,"wsfei"])
	wages=wages[wages>0]
	wages_perc <- individual_quantiles(wages)
  col=cols[which(x$job1digit[ii[1]]==levels(x$job1digit))]
  #ind=which(wages_perc>0)
	lines(log(wages),wages_perc,col=col)
}
```


## Pre-analyses
Initially we use the annual salary variable *wsfei*.
In the next analyses, there are no random effects over the subjects.
The first analysis is a simple linear model:

```{r analyse_annual_salary, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
model12=(wsfei ~ wave +  sex + age_at_interview + edhigh1 + jbmo62  + ancob + anengfn)
fit12 = lm(model12, data=x)
summary(fit12)
anova(fit12)
```

Now we can load the *mgcv* package and use generalized additive models to analyse the data, smoothing the effect of *age_at_interview*. 

For brevity of output, an anova shows that every covariate is significant.

```{r model20, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
library(mgcv)
model20=(wsfei ~ wave +  sex + s(age_at_interview) + edhigh1 + jbmo62 + ancob)
fit20 = gam(model20, data=x)
anova(fit20)
plot(fit20,pages=1,seWithMean=TRUE)
```

Very simple model, it looks like there is a non-linear effect of *age_at_interview*.
Repeat the same analysis smoothing also the wave:

```{r model21, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
library(mgcv)
model21=(wsfei ~ s(wave) +  sex + s(age_at_interview) + edhigh1 + jbmo62 + ancob)
fit21 = gam(model21, data=x)
anova(fit21)
plot(fit21,pages=1,seWithMean=TRUE)
```

It looks we don't need to smooth the wave variable, as the effect is linear.

Finally we can look into the interaction of education and occupation (edhigh1 * jbmo62).

```{r model22, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
library(mgcv)
model22=(wsfei ~ wave +  sex + s(age_at_interview) + edhigh1 * jbmo62 + ancob)
fit22 = gam(model22, data=x)
anova(fit22)
plot(fit22,pages=1,seWithMean=TRUE)
#
#model23=(wsfei ~ wave +  sex + age_at_interview + edhigh1 + jbmo62 + (1|as.factor(xwaveid)))
#no.waves <- by(x,x$xwaveid,nrow)
#good.subjects <- names(no.waves)[no.waves>=12] #5:15420 (163618/186283 records) subjects #4: 16402
#xx <- x[x$xwaveid %in% good.subjects, ]
#fit23 = gam(model23, data=xx)
#Not enough (non-NA) data to do anything
#
#model24=(wsfei ~ s(wave) +  sex + s(age_at_interview) + edhigh1 * jbmo62 + anyoa)
#xx = xx[xx$edqenr>0,]
#fit24 = gam(model24, data=x)
#A term has fewer unique covariate combinations than specified maximum degrees of freedom
```

Results show that the level of education is not significant per se, but only in combination with the occupation.

## Models suggested by Max:

1. wage = costant + demographics + experience(age-anni scuola) + caract.employer(if available) + location + e
2. participation (0=no,1=yes) = costant + demographics + education + young children + wealth + e

### Variables

* wscei: weekly wage ---> replaced with wsfei (annual wage)
~
* ancob  [immigrato o no] --> replaced with ancob3: 3 categories: au, anglo, others
* edcoq  [education in au]
* edqenr [qualifica in au]
* fmfo61 and/or fmmo61 [figlio di operai]
...controlli...
* aneab [conoscenze inglese: missings born in au replaced with 1:very well]
* anyoa [year of arrival]. For non-migrants, replace with 2012-age_2012
* edagels o edhigh1 [years of education] ---> used edhigh1
* esdtl [participation to labour market]
* hgage [age]
* hgsex [sex]
* marital status [mrcurr]
* hhmsr o hhstate [location]
* jbmo62 [occupation]
* jbmwpsz [no employees]
* jbocct [tenure current job]

### Analyses 

In the next two analyses (fit27, fit28), we will fit two identical models with different dependent variables: wsfei (annual salary) and wage_perc (the annual salary is transformed into the percentile specific to the subject's occupation).

In the third fit (fit29), we add the random effects over the subjects (the fit fails when using the annual salary as dependent variable, but succesfully converge with wages_perc).

```{r analyze_annual_salary_complete, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
library(mgcv)
#model25=(wsfei ~ s(wave) +  hgage + sex + s(anyoa) + ancob3 + edhigh1 + jbmo62 + edcoq + edqenr + fmfo61 + fmmo61 + esdtl + mrcurr + hhstate + jbmwpsz + jbocct + aneab)
#fit25 = gam(model25, data=x)
#anova(fit25)
#plot(fit25,pages=1)

#model26=(wsfei ~ s(wave) +  s(hgage) + sex + s(anyoa) + ancob3 + edhigh1 + jbmo62 + edcoq + edqenr + fmfo61 + fmmo61 + esdtl + mrcurr + hhstate + jbmwpsz + jbocct + aneab)
#fit26 = gam(model26, data=x)
#anova(fit26)
#plot(fit26,pages=1)
###anyoa not significant (effect is captured by age)

model27=(wsfei ~      s(wave) +  s(hgage) + sex + ancob3 + edhigh1 + jbmo62 + edcoq + edqenr + fmfo61 + fmmo61 + esdtl + mrcurr + hhstate + jbmwpsz + jbocct + aneab)
fit27 = gam(model27, data=x)
anova(fit27)
plot(fit27,pages=1)

model28=(wages_perc ~ s(wave) +  s(hgage) + sex + ancob3 + edhigh1 + jbmo62 + edcoq + edqenr + fmfo61 + fmmo61 + esdtl + mrcurr + hhstate + jbmwpsz + jbocct + aneab)
fit28 = gam(model28, data=x)
anova(fit28)
plot(fit28,pages=1)

load("fit29.RData")
#fit29 = gamm(model28, random=list(xwaveid=~1), data=x)
#summary(fit29$lme)
anova(fit29$gam)
plot(fit29$gam,pages=1)

#Males vs females
#xm=x[x$sex=="[1] Male",]
#xf=x[x$sex=="[2] Female",]
#model26m=(wsfei ~ s(wave) +  s(hgage) + s(anyoa) + ancob3 + edhigh1 + jbmo62 + edcoq + edqenr + fmfo61 + fmmo61 + esdtl + mrcurr + hhstate + jbmwpsz + jbocct + aneab)
#fit26m = gam(model26m, data=xm)
#anova(fit26m)
#plot(fit26m,pages=1)
#model26f=(wsfei ~ s(wave) +  s(hgage) + s(anyoa) + ancob3 + edhigh1 + jbmo62 + edcoq + edqenr + fmfo61 + fmmo61 + esdtl + mrcurr + hhstate + #jbmwpsz + jbocct + aneab)
#fit26f = gam(model26f, data=xf)
#anova(fit26f)
#plot(fit26f,pages=1)
```

The last fit (fit29) shows that the effect on the wave can be assumed linear and a few covariates are no more significant and can be eliminated from the model. These are:

* Occupation of parents
* ancob3: australian, migrant anglo, migrant other.

This result can be interpreted considering that the dependent variable is the salary percentile of the subject specific to his job. The occupation of the parents and the status of migrant could contribute to choice of the job, but not to the salary in it (hypothesis to test).

## Job satisfaction

Guardando alla tua domanda di OSP e cose che potrebbero essere divertenti, la variabile  latente per eccellenza e' la Job satisfaction. Tra quella per i soldi e per sicurezza (jbmssec) mi sembra ci sia piu' variabilita' per Job satisfaction about pay (jbmspay) e potremmo vedere:
 
1. dall'inizio HILDA, quali sono i lavori dove chi lavora e' piu' felice? [jbmo62]
2. ci sono settori che sono sistematicamente over-paid (qui dovresti vedere in primis mining e finanza. Anche il settore pubblico non e' male)
3. sono piu' felici uomi e donne? [sex]
4. immigrati o nativi? [ancob3]
5. giovani o vecchi? (possibile scala: 25-29; 30-39; 40-49; 50-59; 60+) [s(hgage)]
6. laureati o no? [edcoq --> ...]
7. lavoratori fedeli al'employer o switchers? (tenure: jbocct) 
8. in che stato? (hhstate)
9. e in che tipo di famiglia? (hhtype)
 
detto questo, mi sembra che il funzionale che tu stai usando e' legato al tempo: puo' essere usato anche su intensita', tipo prestigio (jbmoccs): il prestigio ha molte categorie ma e' stato surveyed solo in wave 5. Il che vuol dire mappare le occupation/Prestige scale da wave 5 e 'spararla' alle occupations di tutte le rimanenti waves.

#### Satisfaction for job pay

```{r subset, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
library(ordinal)
xsub=x[,c("xwaveid","hgsex","jbmspay","jbmssec","jbmo62","ancob3","hgage","edcoq","jbocct","hhstate","hhtype","wsfei","wages_perc")]
xsub <- xsub[substr(as.character(xsub$jbmspay),1,1)!="-" & substr(as.character(xsub$jbmssec),1,1)!="-",]
xsub <- xsub[substr(xsub$hhstate,1,2)!="[-",]
xsub=droplevels(xsub)
```

Comparison of the effects on satisfation by salary vs wages_perc.

##### Salary:
```{r satisfaction_job_pay_salary, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
library(ordinal)
fit <- clm(jbmspay ~ hgsex + hgage + ancob3+ hhtype+ jbocct + wsfei, data=xsub)
summary(fit)
```

The model is nearly unidentifiable: very large eigenvalue.

Let's try with wages_perc...

##### wages_perc
```{r satisfaction_job_pay_perc, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
library(ordinal)
fitp <- clm(jbmspay ~ hgsex + hgage + ancob3+ hhtype+ jbocct + wages_perc, data=xsub)
summary(fitp)
#fit <- clm(jbmspay ~ hgsex + jbmo62 + ancob3 + hgage + edcoq + jbocct + hhstate + hhtype + wages_perc, data=xsub)
#summary(fit)
#fitm <- clmm(jbmspay ~ hgsex + jbmo62 + ancob3 + hgage + edcoq + jbocct + hhstate + hhtype + wages_perc + (1|xwaveid), data=xsub)
```

Very good fit.

#### Satisfaction for job security:

##### Salary:

```{r satisfaction_job_security_salary, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
#Works
library(ordinal)
fit <- clm(jbmssec ~ hgsex + hgage + ancob3+ hhtype+ jbocct + wsfei, data=xsub)
summary(fit)
#fit <- clm(jbmssec ~ hgsex + hgage + ancob3+ hhtype+ jbocct + wages_perc + hhstate, data=xsub)
#summary(fit)
#Model is nearly unidentifiable
#fit <- clm(jbmssec ~ hgsex + hgage + ancob3+ hhtype+ jbocct+ edcoq + hhstate, data=xsub)
```

Again, the model is nearly unidentifiable: very large eigenvalue.

##### wages_perc
```{r satisfaction_job_security_perc, eval=T, include=T, echo=F, comment=NA, cache=TRUE}
#Works
library(ordinal)
fit <- clm(jbmssec ~ hgsex + hgage + ancob3+ hhtype+ jbocct + wages_perc, data=xsub)
summary(fit)
```

No problems with this fit. wages_perc works better than wsfei to explain job satisfaction.





































